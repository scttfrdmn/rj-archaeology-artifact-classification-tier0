{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archaeology Quick Start: Artifact Classification\n",
    "\n",
    "**Duration:** 10-30 minutes  \n",
    "**Goal:** Classify archaeological artifacts using a simple machine learning model\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Load and explore archaeological artifact data\n",
    "- Extract features from artifact measurements\n",
    "- Train a classification model to identify artifact types\n",
    "- Evaluate model performance with archaeological metrics\n",
    "- Understand how ML can assist archaeological research\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We'll use a **synthetic archaeological dataset** based on real artifact patterns:\n",
    "- Artifact categories: Pottery, Stone Tools, Metal Objects, Ornaments\n",
    "- Features: Length, width, thickness, weight, material type\n",
    "- 500 artifacts with measurements\n",
    "- Data mimics real archaeological survey results\n",
    "\n",
    "No downloads needed - let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (all pre-installed in Colab/Studio Lab)\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic archaeological artifact data\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def generate_artifact_data(n_samples=500):\n",
    "    \"\"\"Generate synthetic artifact measurements based on real patterns\"\"\"\n",
    "\n",
    "    artifacts = []\n",
    "\n",
    "    # Pottery: typically round, medium-large, clay\n",
    "    n_pottery = n_samples // 4\n",
    "    for _ in range(n_pottery):\n",
    "        artifacts.append(\n",
    "            {\n",
    "                \"type\": \"Pottery\",\n",
    "                \"length_cm\": np.random.normal(15, 4),\n",
    "                \"width_cm\": np.random.normal(12, 3),\n",
    "                \"thickness_cm\": np.random.normal(0.8, 0.2),\n",
    "                \"weight_g\": np.random.normal(250, 80),\n",
    "                \"material\": \"Clay\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Stone Tools: elongated, smaller, stone\n",
    "    n_stone = n_samples // 4\n",
    "    for _ in range(n_stone):\n",
    "        artifacts.append(\n",
    "            {\n",
    "                \"type\": \"Stone Tool\",\n",
    "                \"length_cm\": np.random.normal(8, 2),\n",
    "                \"width_cm\": np.random.normal(4, 1),\n",
    "                \"thickness_cm\": np.random.normal(1.5, 0.4),\n",
    "                \"weight_g\": np.random.normal(150, 50),\n",
    "                \"material\": \"Stone\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Metal Objects: small-medium, heavy, metal\n",
    "    n_metal = n_samples // 4\n",
    "    for _ in range(n_metal):\n",
    "        artifacts.append(\n",
    "            {\n",
    "                \"type\": \"Metal Object\",\n",
    "                \"length_cm\": np.random.normal(10, 3),\n",
    "                \"width_cm\": np.random.normal(3, 1),\n",
    "                \"thickness_cm\": np.random.normal(0.3, 0.1),\n",
    "                \"weight_g\": np.random.normal(180, 60),\n",
    "                \"material\": \"Metal\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Ornaments: small, light, varied materials\n",
    "    n_ornament = n_samples - (n_pottery + n_stone + n_metal)\n",
    "    materials = [\"Bone\", \"Shell\", \"Stone\", \"Metal\"]\n",
    "    for _ in range(n_ornament):\n",
    "        artifacts.append(\n",
    "            {\n",
    "                \"type\": \"Ornament\",\n",
    "                \"length_cm\": np.random.normal(3, 1),\n",
    "                \"width_cm\": np.random.normal(2, 0.5),\n",
    "                \"thickness_cm\": np.random.normal(0.5, 0.2),\n",
    "                \"weight_g\": np.random.normal(15, 10),\n",
    "                \"material\": np.random.choice(materials),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(artifacts)\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "df = generate_artifact_data(500)\n",
    "\n",
    "print(f\"Generated {len(df)} artifact records\")\n",
    "print(f\"\\nArtifact types: {df['type'].unique()}\")\n",
    "print(\"\\nArtifact counts:\")\n",
    "print(df[\"type\"].value_counts())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by artifact type\n",
    "print(\"=== Artifact Measurements by Type ===\")\n",
    "print(\"\\nAverage dimensions:\")\n",
    "print(df.groupby(\"type\")[[\"length_cm\", \"width_cm\", \"thickness_cm\", \"weight_g\"]].mean())\n",
    "\n",
    "print(\"\\nMaterial distribution:\")\n",
    "print(pd.crosstab(df[\"type\"], df[\"material\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize artifact dimensions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Length distribution\n",
    "for artifact_type in df[\"type\"].unique():\n",
    "    data = df[df[\"type\"] == artifact_type][\"length_cm\"]\n",
    "    axes[0, 0].hist(data, alpha=0.5, label=artifact_type, bins=20)\n",
    "axes[0, 0].set_xlabel(\"Length (cm)\")\n",
    "axes[0, 0].set_ylabel(\"Frequency\")\n",
    "axes[0, 0].set_title(\"Artifact Length Distribution\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Width distribution\n",
    "for artifact_type in df[\"type\"].unique():\n",
    "    data = df[df[\"type\"] == artifact_type][\"width_cm\"]\n",
    "    axes[0, 1].hist(data, alpha=0.5, label=artifact_type, bins=20)\n",
    "axes[0, 1].set_xlabel(\"Width (cm)\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "axes[0, 1].set_title(\"Artifact Width Distribution\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Thickness distribution\n",
    "for artifact_type in df[\"type\"].unique():\n",
    "    data = df[df[\"type\"] == artifact_type][\"thickness_cm\"]\n",
    "    axes[1, 0].hist(data, alpha=0.5, label=artifact_type, bins=20)\n",
    "axes[1, 0].set_xlabel(\"Thickness (cm)\")\n",
    "axes[1, 0].set_ylabel(\"Frequency\")\n",
    "axes[1, 0].set_title(\"Artifact Thickness Distribution\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Weight distribution\n",
    "for artifact_type in df[\"type\"].unique():\n",
    "    data = df[df[\"type\"] == artifact_type][\"weight_g\"]\n",
    "    axes[1, 1].hist(data, alpha=0.5, label=artifact_type, bins=20)\n",
    "axes[1, 1].set_xlabel(\"Weight (g)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].set_title(\"Artifact Weight Distribution\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Different artifact types show distinct measurement patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length vs Width scatter plot (colored by type)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for artifact_type in df[\"type\"].unique():\n",
    "    data = df[df[\"type\"] == artifact_type]\n",
    "    ax.scatter(data[\"length_cm\"], data[\"width_cm\"], label=artifact_type, alpha=0.6, s=100)\n",
    "\n",
    "ax.set_xlabel(\"Length (cm)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Width (cm)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Artifact Dimensions: Length vs Width\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Clear clustering by artifact type - good for classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode material as numeric feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_material = LabelEncoder()\n",
    "df[\"material_encoded\"] = le_material.fit_transform(df[\"material\"])\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "feature_columns = [\"length_cm\", \"width_cm\", \"thickness_cm\", \"weight_g\", \"material_encoded\"]\n",
    "X = df[feature_columns]\n",
    "y = df[\"type\"]\n",
    "\n",
    "# Split into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} artifacts\")\n",
    "print(f\"Testing set: {len(X_test)} artifacts\")\n",
    "print(f\"\\nFeatures used: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest classifier\n",
    "print(\"Training Random Forest classifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"feature\": feature_columns, \"importance\": model.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "feature_names = [\"Length\", \"Width\", \"Thickness\", \"Weight\", \"Material\"]\n",
    "ax.barh(feature_names, model.feature_importances_, color=\"steelblue\", alpha=0.8)\n",
    "ax.set_xlabel(\"Importance\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Feature Importance in Artifact Classification\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature importance shows which measurements are most useful for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Overall Accuracy: {accuracy:.2%}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "artifact_types = sorted(df[\"type\"].unique())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=artifact_types,\n",
    "    yticklabels=artifact_types,\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Type\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"True Type\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Confusion Matrix: Artifact Classification\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix shows where the model makes mistakes\")\n",
    "print(\"Diagonal = correct predictions, off-diagonal = misclassifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example predictions\n",
    "n_examples = 10\n",
    "example_indices = np.random.choice(len(X_test), n_examples, replace=False)\n",
    "\n",
    "examples = pd.DataFrame(\n",
    "    {\n",
    "        \"True Type\": y_test.iloc[example_indices].values,\n",
    "        \"Predicted Type\": y_pred[example_indices],\n",
    "        \"Length (cm)\": X_test.iloc[example_indices][\"length_cm\"].values,\n",
    "        \"Width (cm)\": X_test.iloc[example_indices][\"width_cm\"].values,\n",
    "        \"Weight (g)\": X_test.iloc[example_indices][\"weight_g\"].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add correctness indicator\n",
    "examples[\"Correct\"] = examples[\"True Type\"] == examples[\"Predicted Type\"]\n",
    "\n",
    "print(\"=== Example Predictions ===\")\n",
    "print(examples.to_string(index=False))\n",
    "\n",
    "correct_predictions = examples[\"Correct\"].sum()\n",
    "print(f\"\\n{correct_predictions}/{n_examples} predictions correct in this sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHAEOLOGICAL CLASSIFICATION ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset: {len(df)} artifacts across {len(df['type'].unique())} categories\")\n",
    "print(\"\\nArtifact Types:\")\n",
    "for artifact_type in sorted(df[\"type\"].unique()):\n",
    "    count = len(df[df[\"type\"] == artifact_type])\n",
    "    print(f\"  • {artifact_type}: {count} artifacts\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  • Overall Accuracy: {accuracy:.1%}\")\n",
    "print(f\"  • Training Set: {len(X_train)} artifacts\")\n",
    "print(f\"  • Testing Set: {len(X_test)} artifacts\")\n",
    "\n",
    "print(\"\\nMost Important Features:\")\n",
    "for _i, row in feature_importance.head(3).iterrows():\n",
    "    feature_name = row[\"feature\"].replace(\"_\", \" \").title()\n",
    "    print(f\"  • {feature_name}: {row['importance']:.3f}\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"  • Machine learning can effectively classify artifacts based on measurements\")\n",
    "print(\"  • Physical dimensions (length, width, weight) are strong predictors\")\n",
    "print(\"  • Material type also contributes to accurate classification\")\n",
    "print(f\"  • Model achieves {accuracy:.1%} accuracy on unseen test data\")\n",
    "\n",
    "print(\"\\nArchaeological Applications:\")\n",
    "print(\"  • Automated artifact categorization for large collections\")\n",
    "print(\"  • Consistent classification across multiple excavation sites\")\n",
    "print(\"  • Identification of unusual or hybrid artifact forms\")\n",
    "print(\"  • Support for archaeological typology development\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Learned\n",
    "\n",
    "In just 10-30 minutes, you:\n",
    "\n",
    "1. Loaded and explored archaeological artifact data\n",
    "2. Visualized measurement patterns across artifact types\n",
    "3. Trained a machine learning classifier using Random Forest\n",
    "4. Evaluated model performance with multiple metrics\n",
    "5. Understood how ML can assist archaeological classification\n",
    "6. Identified the most important features for artifact identification\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Ready for More?\n",
    "\n",
    "**Tier 1: SageMaker Studio Lab (4-8 hours, free)**\n",
    "- Analyze multi-site archaeological data (imagery, LiDAR, geophysical)\n",
    "- Train deep learning models on artifact images\n",
    "- Use persistent storage for 10GB+ datasets\n",
    "- Build ensemble models with saved checkpoints\n",
    "- Cross-site comparative analysis\n",
    "\n",
    "**Tier 2: AWS Starter (4-6 hours, $10-25)**\n",
    "- Store artifact imagery in S3\n",
    "- Process images with Lambda functions\n",
    "- Train models with SageMaker\n",
    "- Set up automated artifact detection pipeline\n",
    "\n",
    "**Tier 3: Production Infrastructure (5-7 days, $100-500/month)**\n",
    "- Multi-site datasets (100GB+)\n",
    "- Distributed processing with SageMaker\n",
    "- Real-time artifact identification API\n",
    "- Integration with archaeological databases\n",
    "- Full CloudFormation deployment\n",
    "\n",
    "## Learn More\n",
    "\n",
    "- **Archaeological Data Science:** [Open Context](https://opencontext.org/)\n",
    "- **Digital Archaeology:** [Archaeological Institute of America](https://www.archaeological.org/)\n",
    "- **ML in Archaeology:** Recent papers on automated artifact classification\n",
    "\n",
    "---\n",
    "\n",
    "**Generated with [Claude Code](https://claude.com/claude-code)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
